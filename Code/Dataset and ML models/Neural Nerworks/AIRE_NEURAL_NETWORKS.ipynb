{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the dependencies\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cijena</th>\n",
       "      <th>stanje</th>\n",
       "      <th>broj_kvadrata</th>\n",
       "      <th>sprat</th>\n",
       "      <th>namjesten</th>\n",
       "      <th>broj_soba</th>\n",
       "      <th>grijanje</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>180000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>73000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>88000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>95000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     cijena  stanje  broj_kvadrata  sprat  namjesten  broj_soba  grijanje\n",
       "0   35000.0       0           40.0     -1        0.0        1.0         1\n",
       "1  180000.0       0           65.0     -1        0.0        2.0         1\n",
       "2   73000.0       0           38.0     -1        0.0        2.0         2\n",
       "3   88000.0       0           68.0     -1        0.0        3.0         2\n",
       "4   95000.0       0           68.0     -1        0.0        3.0         2"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load the data set\n",
    "df = pd.read_csv(r\"C:\\Users\\MyPC\\Desktop\\dataset_nn.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.50e+04, 0.00e+00, 4.00e+01, ..., 0.00e+00, 1.00e+00, 1.00e+00],\n",
       "       [1.80e+05, 0.00e+00, 6.50e+01, ..., 0.00e+00, 2.00e+00, 1.00e+00],\n",
       "       [7.30e+04, 0.00e+00, 3.80e+01, ..., 0.00e+00, 2.00e+00, 2.00e+00],\n",
       "       ...,\n",
       "       [1.30e+05, 0.00e+00, 5.00e+01, ..., 1.00e+00, 2.00e+00, 2.00e+00],\n",
       "       [1.65e+05, 0.00e+00, 7.20e+01, ..., 1.00e+00, 3.00e+00, 2.00e+00],\n",
       "       [1.95e+05, 0.00e+00, 7.60e+01, ..., 1.00e+00, 4.00e+00, 2.00e+00]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Convert the data into an array\n",
    "dataset = df.values\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cijena           False\n",
       "stanje           False\n",
       "broj_kvadrata    False\n",
       "sprat            False\n",
       "namjesten        False\n",
       "broj_soba        False\n",
       "grijanje         False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().any() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the data set \n",
    "X = dataset[:,1:8] #train data\n",
    "Y = dataset[:,0]   #test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.        , -0.96414653, -1.        , -1.        , -0.6       ,\n",
       "        -1.        ],\n",
       "       [-1.        , -0.92517537, -1.        , -1.        , -0.2       ,\n",
       "        -1.        ],\n",
       "       [-1.        , -0.96726422, -1.        , -1.        , -0.2       ,\n",
       "        -0.5       ],\n",
       "       ...,\n",
       "       [-1.        , -0.94855807,  0.9       ,  1.        , -0.2       ,\n",
       "        -0.5       ],\n",
       "       [-1.        , -0.91426345,  1.        ,  1.        ,  0.2       ,\n",
       "        -0.5       ],\n",
       "       [-1.        , -0.90802806,  1.        ,  1.        ,  0.6       ,\n",
       "        -0.5       ]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#the min-max scaler method scales the dataset so that all the input features lie between 0 and 1 inclusive\n",
    "from sklearn import preprocessing\n",
    "min_max_scaler = preprocessing.MinMaxScaler(feature_range=(-1, 1))\n",
    "X_scale = min_max_scaler.fit_transform(X)\n",
    "X_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1787, 6) (223, 6) (224, 6) (1787,) (223,) (224,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Split the data into 80% training and 20% (testing (10%) and validation (10%))\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val_and_test, Y_train, Y_val_and_test = train_test_split(X_scale, Y, test_size=0.2)\n",
    "X_val, X_test, Y_val, Y_test = train_test_split(X_val_and_test, Y_val_and_test, test_size=0.5)\n",
    "\n",
    "#the training set has 1787 data points while the validation and test set has 223 data points each. The X variables have 6 input features, while the Y variables has one feature to predict.\n",
    "print(X_train.shape, X_val.shape, X_test.shape, Y_train.shape, Y_val.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build the model and architecture of the deep neural network\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(6,)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how well the model did on training , and then try to improve on it using the optimizer\n",
    "model.compile(optimizer='sgd',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "56/56 [==============================] - 2s 29ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "56/56 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "56/56 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 4/100\n",
      "56/56 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 5/100\n",
      "56/56 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 6/100\n",
      "56/56 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 7/100\n",
      "56/56 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 8/100\n",
      "56/56 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 9/100\n",
      "56/56 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 10/100\n",
      "56/56 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 11/100\n",
      "56/56 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 12/100\n",
      "56/56 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 13/100\n",
      "56/56 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 14/100\n",
      "56/56 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 15/100\n",
      "56/56 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 16/100\n",
      "56/56 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 17/100\n",
      "56/56 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 18/100\n",
      "56/56 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 19/100\n",
      "56/56 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 20/100\n",
      "56/56 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 21/100\n",
      "56/56 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 22/100\n",
      "56/56 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 23/100\n",
      "56/56 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 24/100\n",
      "56/56 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 25/100\n",
      "56/56 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 26/100\n",
      "56/56 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 27/100\n",
      "56/56 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 28/100\n",
      "56/56 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 29/100\n",
      "56/56 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 30/100\n",
      "56/56 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 31/100\n",
      "56/56 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 32/100\n",
      "56/56 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 33/100\n",
      "56/56 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 34/100\n",
      "56/56 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 35/100\n",
      "56/56 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 36/100\n",
      "56/56 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 37/100\n",
      "56/56 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 38/100\n",
      "56/56 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 39/100\n",
      "56/56 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 40/100\n",
      "56/56 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 41/100\n",
      "56/56 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 42/100\n",
      "56/56 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 43/100\n",
      "56/56 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 44/100\n",
      "56/56 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 45/100\n",
      "56/56 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 46/100\n",
      "56/56 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 47/100\n",
      "56/56 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 48/100\n",
      "56/56 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 49/100\n",
      "56/56 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 50/100\n",
      "56/56 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 51/100\n",
      "56/56 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 52/100\n",
      "56/56 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 53/100\n",
      "56/56 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 54/100\n",
      "56/56 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 55/100\n",
      "56/56 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 56/100\n",
      "56/56 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 57/100\n",
      "56/56 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/100\n",
      "56/56 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 59/100\n",
      "56/56 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 60/100\n",
      "56/56 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 61/100\n",
      "56/56 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 62/100\n",
      "56/56 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 63/100\n",
      "56/56 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 64/100\n",
      "56/56 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 65/100\n",
      "56/56 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 66/100\n",
      "56/56 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 67/100\n",
      "56/56 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 68/100\n",
      "56/56 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 69/100\n",
      "56/56 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 70/100\n",
      "56/56 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 71/100\n",
      "56/56 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 72/100\n",
      "56/56 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 73/100\n",
      "56/56 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 74/100\n",
      "56/56 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 75/100\n",
      "56/56 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 76/100\n",
      "56/56 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 77/100\n",
      "56/56 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 78/100\n",
      "56/56 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 79/100\n",
      "56/56 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 80/100\n",
      "56/56 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 81/100\n",
      "56/56 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 82/100\n",
      "56/56 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 83/100\n",
      "56/56 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 84/100\n",
      "56/56 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 85/100\n",
      "56/56 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 86/100\n",
      "56/56 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 87/100\n",
      "56/56 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 88/100\n",
      "56/56 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 89/100\n",
      "56/56 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 90/100\n",
      "56/56 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 91/100\n",
      "56/56 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 92/100\n",
      "56/56 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 93/100\n",
      "56/56 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 94/100\n",
      "56/56 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 95/100\n",
      "56/56 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 96/100\n",
      "56/56 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 97/100\n",
      "56/56 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 98/100\n",
      "56/56 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 99/100\n",
      "56/56 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 100/100\n",
      "56/56 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "#Train the model\n",
    "hist = model.fit(X_train, Y_train,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_val, Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#output the accuracy\n",
    "model.evaluate(X_test, Y_test)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[ 95000. 101000. 262000. 398000. 235000. 142900. 135000. 226000. 450000.\n",
      "  74000. 150000. 120000. 250000.  75000. 169000. 220000. 139000. 160000.\n",
      " 157000.  89900.  75000. 154000. 290000. 116000. 180000. 530000. 189000.\n",
      " 245000. 185000.  98000.  85000. 125000. 198000. 137000. 125000. 130000.\n",
      "  75000. 206000.  69900.  99000.  74000. 110000. 145000. 158700. 139000.\n",
      " 375000. 485000. 248500. 270000. 143000. 139000.  60000. 350000. 230000.\n",
      " 139900. 257000. 229000. 125000. 180000. 119999.  99200. 151000. 200000.\n",
      " 300000. 248000. 460000. 165000. 109000.  69900. 114000.  55000. 164000.\n",
      " 104000. 278000. 380000.  74000.  79000. 139000. 165000. 184555. 110252.\n",
      " 463000. 362000. 230000. 105000. 162776. 299000. 351000. 115000. 320000.\n",
      " 129000. 359128.  95000. 315000. 185000. 123000. 100000. 600000. 139500.\n",
      " 108000. 189000. 164000. 150000. 398000. 140000. 250000. 127950. 230000.\n",
      "  77000. 135000. 110000.  79000.  52000. 143000. 130000. 188000. 265000.\n",
      " 140000. 125000. 110000. 164000.  77000. 106600. 115000. 104000. 115000.\n",
      "  93500. 180000. 176000.  85700. 203000. 170000. 149000. 185000. 300000.\n",
      " 125000. 146000. 600000. 283500.  79000. 215000. 137000. 390000. 210000.\n",
      " 280000. 135000. 337000. 145000. 190000. 135000. 160000.  68000. 170000.\n",
      " 110000. 152791. 186000. 139000. 380000. 212000.  85000. 139500. 129000.\n",
      " 110000.  27000.  62000. 103000. 126000. 320000. 125000.  83000. 155000.\n",
      "  85000. 164900. 530000. 226000. 180000. 130000. 285000. 349000. 165000.\n",
      " 130000. 259000. 230000.  89000. 104000. 320000. 102000. 360000.  92700.\n",
      " 140000. 175000. 119000. 155000. 106600.  74000. 270000.  82000. 180000.\n",
      " 256000. 130000.  72000. 160000. 103950. 165000.  95000. 300000. 229755.\n",
      " 226000. 290000. 165000. 137000. 154900.  60000. 158000. 108000. 207000.\n",
      " 280000. 133000. 450000. 265000. 113351. 330000. 130000. 170000.]\n"
     ]
    }
   ],
   "source": [
    "#Make a prediction\n",
    "prediction = model.predict(X_test)\n",
    "prediction  = [1 if y>=0.5 else 0 for y in prediction] #Threshold\n",
    "print(prediction)\n",
    "print(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#visualize the training loss and the validation loss to see if the model is overfitting\n",
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Val'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'acc'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-aebc4220fa54>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#visualize the training accuracy and the validation accuracy to see if the model is overfitting\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'acc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_acc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Model accuracy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Accuracy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'acc'"
     ]
    }
   ],
   "source": [
    "#visualize the training accuracy and the validation accuracy to see if the model is overfitting\n",
    "plt.plot(hist.history['acc'])\n",
    "plt.plot(hist.history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Val'], loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
